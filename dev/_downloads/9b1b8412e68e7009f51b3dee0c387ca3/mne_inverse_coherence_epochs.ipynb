{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compute coherence in source space using a MNE inverse solution\n\nThis example computes the coherence between a seed in the left\nauditory cortex and the rest of the brain based on single-trial\nMNE-dSPM inverse solutions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Martin Luessi <mluessi@nmr.mgh.harvard.edu>\n#\n# License: BSD (3-clause)\n\nimport mne\nimport numpy as np\nfrom mne.datasets import sample\nfrom mne.minimum_norm import apply_inverse, apply_inverse_epochs, read_inverse_operator\n\nfrom mne_connectivity import seed_target_indices, spectral_connectivity_epochs\n\nprint(__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read the data\n\nFirst we'll read in the sample MEG data that we'll use for computing\ncoherence between channels. We'll convert this into epochs in order to\ncompute the event-related coherence.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = sample.data_path()\nsubjects_dir = data_path / \"subjects\"\nfname_inv = data_path / \"MEG/sample/sample_audvis-meg-oct-6-meg-inv.fif\"\nfname_raw = data_path / \"MEG/sample/sample_audvis_filt-0-40_raw.fif\"\nfname_event = data_path / \"MEG/sample/sample_audvis_filt-0-40_raw-eve.fif\"\nlabel_name_lh = \"Aud-lh\"\nfname_label_lh = data_path / f\"MEG/sample/labels/{label_name_lh}.label\"\n\nevent_id, tmin, tmax = 1, -0.2, 0.5\nmethod = \"dSPM\"  # use dSPM method (could also be MNE or sLORETA)\n\n# Load data.\ninverse_operator = read_inverse_operator(fname_inv)\nlabel_lh = mne.read_label(fname_label_lh)\nraw = mne.io.read_raw_fif(fname_raw)\nevents = mne.read_events(fname_event)\n\n# Add a bad channel.\nraw.info[\"bads\"] += [\"MEG 2443\"]\n\n# pick MEG channels.\npicks = mne.pick_types(\n    raw.info, meg=True, eeg=False, stim=False, eog=True, exclude=\"bads\"\n)\n\n# Read epochs.\nepochs = mne.Epochs(\n    raw,\n    events,\n    event_id,\n    tmin,\n    tmax,\n    picks=picks,\n    baseline=(None, 0),\n    reject=dict(mag=4e-12, grad=4000e-13, eog=150e-6),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choose channels for coherence estimation\n\nNext we'll calculate our channel sources. Then we'll find the most active\nvertex in the left auditory cortex, which we will later use as seed for the\nconnectivity computation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "snr = 3.0\nlambda2 = 1.0 / snr**2\nevoked = epochs.average()\nstc = apply_inverse(evoked, inverse_operator, lambda2, method, pick_ori=\"normal\")\n\n# Restrict the source estimate to the label in the left auditory cortex.\nstc_label = stc.in_label(label_lh)\n\n# Find number and index of vertex with most power.\nsrc_pow = np.sum(stc_label.data**2, axis=1)\nseed_vertno = stc_label.vertices[0][np.argmax(src_pow)]\nseed_idx = np.searchsorted(stc.vertices[0], seed_vertno)  # index in orig stc\n\n# Generate index parameter for seed-based connectivity analysis.\nn_sources = stc.data.shape[0]\nindices = seed_target_indices([seed_idx], np.arange(n_sources))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the inverse solution for each epoch. By using \"return_generator=True\"\nstcs will be a generator object instead of a list. This allows us so to\ncompute the coherence without having to keep all source estimates in memory.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "snr = 1.0  # use lower SNR for single epochs\nlambda2 = 1.0 / snr**2\nstcs = apply_inverse_epochs(\n    epochs, inverse_operator, lambda2, method, pick_ori=\"normal\", return_generator=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the coherence between sources\n\nNow we are ready to compute the coherence in the alpha and beta band.\nfmin and fmax specify the lower and upper freq. for each band, respectively.\n\nTo speed things up, we use 2 parallel jobs and use mode='fourier', which\nuses a FFT with a Hanning window to compute the spectra (instead of\na multitaper estimation, which has a lower variance but is slower).\nBy using faverage=True, we directly average the coherence in the alpha and\nbeta band, i.e., we will only get 2 frequency bins.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fmin = (8.0, 13.0)\nfmax = (13.0, 30.0)\nsfreq = raw.info[\"sfreq\"]  # the sampling frequency\n\ncoh = spectral_connectivity_epochs(\n    stcs,\n    method=\"coh\",\n    mode=\"fourier\",\n    indices=indices,\n    sfreq=sfreq,\n    fmin=fmin,\n    fmax=fmax,\n    faverage=True,\n    n_jobs=1,\n)\nfreqs = coh.freqs\n\nprint(\"Frequencies in Hz over which coherence was averaged for alpha: \")\nprint(freqs[0])\nprint(\"Frequencies in Hz over which coherence was averaged for beta: \")\nprint(freqs[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate coherence sources and plot\n\nFinally, we'll generate a SourceEstimate with the coherence. This is simple\nsince we used a single seed. For more than one seed we would have to choose\none of the slices within ``coh``.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We use a hack to save the frequency axis as time.</p></div>\n\nFinally, we'll plot this source estimate on the brain.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tmin = np.mean(freqs[0])\ntstep = np.mean(freqs[1]) - tmin\ncoh_stc = mne.SourceEstimate(\n    coh.get_data(),\n    vertices=stc.vertices,\n    tmin=1e-3 * tmin,\n    tstep=1e-3 * tstep,\n    subject=\"sample\",\n)\n\n# Now we can visualize the coherence using the plot method.\nbrain = coh_stc.plot(\n    \"sample\",\n    \"inflated\",\n    \"both\",\n    time_label=\"Coherence %0.1f Hz\",\n    subjects_dir=subjects_dir,\n    clim=dict(kind=\"value\", lims=(0.25, 0.4, 0.65)),\n)\nbrain.show_view(\"lateral\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}