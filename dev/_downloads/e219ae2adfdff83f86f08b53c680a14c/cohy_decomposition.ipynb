{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multivariate decomposition for efficient connectivity analysis\n\nThis example demonstrates how the tools in the decoding module can be used to\ndecompose data into the most relevant components of connectivity and used for\na computationally efficient multivariate analysis of connectivity, such as in\nbrain-computer interface (BCI) applications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Thomas S. Binns <t.s.binns@outlook.com>\n# License: BSD (3-clause)\n# sphinx_gallery_thumbnail_number = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom mne_connectivity import (\n    make_signals_in_freq_bands,\n    seed_target_indices,\n    spectral_connectivity_epochs,\n)\nfrom mne_connectivity.decoding import CoherencyDecomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Background\n\nMultivariate forms of signal analysis allow you to simultaneously consider\nthe activity of multiple signals. In the case of connectivity, the\ninteraction between multiple sensors can be analysed at once and the strongest\ncomponents of this interaction captured in a lower-dimensional set of connectivity\nspectra. This approach brings not only practical benefits (e.g. easier\ninterpretability of results from the dimensionality reduction), but can also offer\nmethodological improvements (e.g. enhanced signal-to-noise ratio and reduced bias).\n\nCoherency-based methods are popular approaches for analysing connectivity, capturing\ncorrelations between signals in the frequency domain. Various coherency-based\nmultivariate methods exist, including: canonical coherency (CaCoh; multivariate\nmeasure of coherency/coherence) :footcite:`VidaurreEtAl2019`; and maximised imaginary\ncoherency (MIC; multivariate measure of the imaginary part of coherency)\n:footcite:`EwaldEtAl2012`.\n\nThese methods are described in detail in the following examples:\n - comparison of coherency-based methods - :doc:`../compare_coherency_methods`\n - CaCoh - :doc:`../cacoh`\n - MIC - :doc:`../mic_mim`\n\nThe CaCoh and MIC methods work by finding spatial filters that decompose the data into\ncomponents of connectivity, and applying them to the data. With the implementations\noffered in :func:`~mne_connectivity.spectral_connectivity_epochs` and\n:func:`~mne_connectivity.spectral_connectivity_time`, the filters are fit for each\nfrequency separately, and the filters are only applied to the same data they are fit\non.\n\nUnfortunately, fitting filters for each frequency bin can be computationally\nexpensive, which may prohibit the use of these techniques, e.g. in real-time BCI\nsetups where the rapid analysis of data is paramount, or even in offline analyses\nwith huge datasets.\n\nThese issues are addressed by the\n:class:`~mne_connectivity.decoding.CoherencyDecomposition` class of the decoding\nmodule. Here, the filters are fit for a given frequency band collectively (not each\nfrequency bin!) and are stored, allowing them to be applied to the same data they were\nfit on (e.g. for offline analyses of huge datasets) or to new data (e.g. for online\nanalyses of streamed data).\n\nIn this example, we show how the tools of the decoding module compare to the standard\n``spectral_connectivity_...()`` functions in terms of their run time, and their\nability to decompose data into connectivity components.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case 1: Fitting to and transforming the same data\nThe first use of the decoding module class we will explore is fitting filters to one\npiece of data and transforming that same piece of data. This is a similar process to\nthe ``spectral_connectivity_...()`` functions, but with the increased efficiency of\nfitting filters to a single frequency band as opposed to each frequency bin.\n\nTo demonstrate this approach, we simulate some connectivity between two groups of\nsignals at 15-20 Hz as 60 two-second-long epochs. Here, we focus on fitting filters to\nand transforming the first 30 epochs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define simulation settings\nN_SEEDS = 10\nN_TARGETS = 15\n\nFMIN = 15\nFMAX = 20\n\nN_EPOCHS = 60\n\n# Simulate data\nepochs = make_signals_in_freq_bands(\n    n_seeds=N_SEEDS,\n    n_targets=N_TARGETS,\n    freq_band=(FMIN, FMAX),\n    n_epochs=N_EPOCHS,\n    n_times=200,\n    sfreq=100,\n    snr=0.2,\n    rng_seed=44,\n)\n\nseeds = np.arange(N_SEEDS)\ntargets = np.arange(N_TARGETS) + N_SEEDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To fit the filters, we instantiate the\n:class:`~mne_connectivity.decoding.CoherencyDecomposition` class with:\n\n- the information about the data being fit/transformed (using an :class:`~mne.Info`\n  object);\n\n- the type of connectivity we want to decompose (here CaCoh);\n\n- the frequency band of the components we want to decompose (here 15-20 Hz);\n\n- and the channel indices of the seeds and targets.\n\nWe use the CaCoh method since zero time-lag interactions are not present (See\n:doc:`../compare_coherency_methods` for more information).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Instantiate decomposition class\ncacoh = CoherencyDecomposition(\n    info=epochs.info,\n    method=\"cacoh\",\n    indices=(seeds, targets),\n    mode=\"multitaper\",\n    fmin=FMIN,\n    fmax=FMAX,\n    rank=(3, 3),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are two equivalent options for fitting and transforming the same data: 1)\npassing the data to the :meth:`~mne_connectivity.decoding.CoherencyDecomposition.fit`\nand :meth:`~mne_connectivity.decoding.CoherencyDecomposition.transform` methods\nsequentially; or 2) using the combined\n:meth:`~mne_connectivity.decoding.CoherencyDecomposition.fit_transform` method. We use\nthe latter approach below, passing in the first 30 epochs of data to fit to and\ntransform.\n\nThe transformed data has shape ``(epochs x components*2 x times)``, where the new\n'channels' are organised as the seed components, then target components. For\nconvenience, the\n:meth:`~mne_connectivity.decoding.CoherencyDecomposition.get_transformed_indices`\nmethod can be used to get the ``indices`` of the transformed data for use in the\n``spectral_connectivity_...()`` functions.\n\nTo compute connectivity of the transformed data, it is simply a case of passing to the\n``spectral_connectivity_...()`` functions: the transformed data; the indices returned\nfrom\n:meth:`~mne_connectivity.decoding.CoherencyDecomposition.get_transformed_indices`; and\nthe corresponding bivariate method (``\"coh\"`` and ``\"cohy\"`` for CaCoh; ``\"imcoh\"``\nfor MIC).\n\nFor comparison, we will also compute connectivity using the standard CaCoh approach of\nthe ``spectral_connectivity_...()`` functions, as well as bivariate coherence, to show\nthe signal-to-noise ratio benefits of the multivariate approach.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Fit & transform data using decomposition class\nstart = time.time()\nepochs_transformed = cacoh.fit_transform(epochs[: N_EPOCHS // 2].get_data())\n# Compute connectivity using spec_conn function\ncon_cacoh_0_29_class = spectral_connectivity_epochs(\n    epochs_transformed,\n    method=\"coh\",\n    indices=cacoh.get_transformed_indices(),\n    fmin=5,\n    fmax=35,\n    sfreq=epochs.info[\"sfreq\"],\n)\nclass_duration = (time.time() - start) * 1000\n\n# Fit, transform, and compute connectivity using spec_conn function\nstart = time.time()\ncon_cacoh_0_29_func = spectral_connectivity_epochs(\n    epochs[: N_EPOCHS // 2],\n    method=\"cacoh\",\n    indices=([seeds], [targets]),\n    fmin=5,\n    fmax=35,\n    rank=([3], [3]),\n)\nfunc_duration = (time.time() - start) * 1000\n\n# Compute bivariate connectivity for comparison\ncon_coh_0_29 = spectral_connectivity_epochs(\n    epochs[: N_EPOCHS // 2],\n    method=\"coh\",\n    indices=seed_target_indices(seeds, targets),\n    fmin=5,\n    fmax=35,\n    rank=([3], [3]),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the connectivity, the CaCoh results derived from the decomposition class and\nthe ``spectral_connectivity_...()`` functions are very similar, showing a peak in\nconnectivity at 15-20 Hz. The results are not identical however, due to the band- vs.\nbin-wise filter fitting approaches. In both cases, the connectivity extracted is of a\nmuch greater magnitude compared to bivariate coherence.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot connectivity\nax = plt.subplot(111)\nax.plot(\n    con_cacoh_0_29_func.freqs,\n    np.abs(con_cacoh_0_29_func.get_data()[0]),\n    label=\"CaCoh (spec_conn\\nfunction)\",\n)\nax.plot(con_coh_0_29.freqs, np.mean(con_coh_0_29.get_data(), axis=0), label=\"Coh\")\nax.plot(\n    con_cacoh_0_29_class.freqs,\n    np.abs(con_cacoh_0_29_class.get_data()[0]),\n    label=\"CaCoh (decomposition\\nclass)\",\n)\nax.axvspan(FMIN, FMAX, color=\"grey\", alpha=0.2, label=\"Fitted freq. band\")\nax.set_xlabel(\"Frequency (Hz)\")\nax.set_ylabel(\"Connectivity (A.U.)\")\nax.set_title(\"Epochs 1-30\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the above figure, notice also how the CaCoh results from the decomposition class\nshow less connectivity outside of the 15-20 Hz range compared to the CaCoh results of\nthe ``spectral_connectivity_...()`` functions.\n\nThis shows the risk of overfitting filters to noise in the data, even when no genuine\nconnectivity is present. This problem can be mitigated by fitting filters to only\nthose frequencies where you expect connectivity to be present, e.g. as is done with\nthe decomposition class.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition to assessing the validity of the approach, we can also look at the time\ntaken to run the analysis. Doing so, we see that the decomposition class is much\nfaster than the ``spectral_connectivity_...()`` functions, thanks to the fact that the\nfilters are fit to a single frequency band and not each frequency bin.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Show compute times of analyses\nprint(\n    \"Time to fit, transform, and compute connectivity (decomposition class): \"\n    f\"{class_duration:.0f} ms\"\n)\nprint(\n    f\"Time to fit, transform, and compute connectivity (spec_conn function): \"\n    f\"{func_duration:.0f} ms\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Altogether, the decomposition class offers an efficient way to analyse connectivity\nin a specific frequency band when fitting filters to and transforming a single piece\nof data.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case 2: Fitting to and transforming different data\nAnother way we can use the decomposition class is by taking the filters trained on one\npiece of data and applying them to another piece of data. Continuing with our\nsimulated data example, we can reuse the\n:class:`~mne_connectivity.decoding.CoherencyDecomposition` instance we made earlier,\nas it already contains filters fit on the first 30 epochs of data. We can then apply\nthose filters to the last 30 epochs of data using the\n:meth:`~mne_connectivity.decoding.CoherencyDecomposition.transform` method, extracting\nthis same connectivity component.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use filters from first 30 epochs to transform data from last 30 epochs\nepochs_transformed = cacoh.transform(epochs[N_EPOCHS // 2 :].get_data())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now compute connectivity in the last 30 epochs of the transformed data, which\nfor reference we will compare to connectivity computed using the\n``spectral_connectivity_...()`` functions, as well as bivariate coherence to again\ndemonstrate the signal-to-noise ratio enhancements the multivariate approach offers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Fit, transform, and compute connectivity for last 30 epochs using spec_conn function\ncon_cacoh_30_60_func = spectral_connectivity_epochs(\n    epochs[N_EPOCHS // 2 :],\n    method=\"cacoh\",\n    indices=([seeds], [targets]),\n    fmin=5,\n    fmax=35,\n    rank=([3], [3]),\n)\n\n# Compute connectivity for last 30 epochs transformed with filters from first 30 epochs\ncon_cacoh_30_60_class = spectral_connectivity_epochs(\n    epochs_transformed,\n    method=\"coh\",\n    indices=cacoh.get_transformed_indices(),\n    fmin=5,\n    fmax=35,\n    sfreq=epochs.info[\"sfreq\"],\n)\n\n# Compute bivariate connectivity of last 30 epochs for comparison\ncon_coh_30_60 = spectral_connectivity_epochs(\n    epochs[N_EPOCHS // 2 :],\n    method=\"coh\",\n    indices=seed_target_indices(seeds, targets),\n    fmin=5,\n    fmax=35,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the connectivity profile of the transformed data using filters fit on\nthe first 30 epochs is very similar to the connectivity profile when using filters fit\non the last 30 epochs itself. This shows that the filters are generalisable, able to\nextract the same components of connectivity which they were trained on from new data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot connectivity\nax = plt.subplot(111)\nax.plot(\n    con_cacoh_30_60_func.freqs,\n    np.abs(con_cacoh_30_60_func.get_data()[0]),\n    label=\"CaCoh (spec_conn\\nfunction)\",\n)\nax.plot(con_coh_30_60.freqs, np.mean(con_coh_30_60.get_data(), axis=0), label=\"Coh\")\nax.plot(\n    con_cacoh_30_60_class.freqs,\n    np.abs(con_cacoh_30_60_class.get_data()[0]),\n    label=\"CaCoh (decomposition\\nclass)\",\n)\nax.axvspan(FMIN, FMAX, color=\"grey\", alpha=0.2, label=\"Fitted freq. band\")\nax.set_xlabel(\"Frequency (Hz)\")\nax.set_ylabel(\"Connectivity (A.U.)\")\nax.set_title(\"Epochs 31-60\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, notice how the CaCoh results from the decomposition class show less\nconnectivity outside of the 15-20 Hz range compared to the CaCoh results of the\n``spectral_connectivity_...()`` functions.\n\nWe can also look at the time taken to run the analysis. Below we present a scenario\nresembling an online sliding window approach typical of a BCI system. We consider the\nfirst 30 epochs to be the training data that the filters should be fit to, and the\nlast 30 epochs to be the windows of data that the filters should be applied to,\ntransforming and computing the connectivity of each window (epoch) of data\nsequentially.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Instantiate decomposition class\ncacoh = CoherencyDecomposition(\n    info=epochs.info,\n    method=\"cacoh\",\n    indices=(seeds, targets),\n    mode=\"multitaper\",\n    fmin=FMIN,\n    fmax=FMAX,\n    rank=(3, 3),\n)\n\n# Time fitting of filters\nstart_fit = time.time()\ncacoh.fit(epochs[: N_EPOCHS // 2].get_data())\nfit_duration = (time.time() - start_fit) * 1000\n\n# Time transforming data of each epoch iteratively\nstart_transform = time.time()\nfor epoch in epochs[N_EPOCHS // 2 :]:\n    epoch_transformed = cacoh.transform(epoch)\n    spectral_connectivity_epochs(\n        np.expand_dims(epoch_transformed, axis=0),\n        method=\"coh\",\n        indices=cacoh.get_transformed_indices(),\n        fmin=5,\n        fmax=35,\n        sfreq=epochs.info[\"sfreq\"],\n    )\ntransform_duration = (time.time() - start_transform) * 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Doing so, we see that once the filters have been fit, it takes only a few milliseconds\nto transform each window of data and compute its connectivity.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Show compute times of decomposition class\nprint(f\"Time to fit filters: {fit_duration:.0f} ms\")\nprint(f\"Time to transform data and compute connectivity: {transform_duration:.0f} ms\")\nprint(f\"Total time: {fit_duration + transform_duration:.0f} ms\")\n\nprint(\n    \"\\nTime to transform data and compute connectivity per epoch (window): \",\n    f\"{transform_duration/(N_EPOCHS//2):.0f} ms\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In contrast, here we follow the same sequential window approach, but fit filters to\neach window separately rather than using a pre-computed set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Time fitting and transforming data of each epoch iteratively\nstart_fit_transform = time.time()\nfor epoch in epochs[N_EPOCHS // 2 :]:\n    spectral_connectivity_epochs(\n        np.expand_dims(epoch, axis=0),\n        method=\"cacoh\",\n        indices=([seeds], [targets]),\n        fmin=5,\n        fmax=35,\n        sfreq=epochs.info[\"sfreq\"],\n        rank=([3], [3]),\n    )\nfit_transform_duration = (time.time() - start_fit_transform) * 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Naturally, the process of fitting and transforming the data for each window is\nconsiderably slower.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Show compute times of spec_conn function\nprint(\n    f\"Time to fit, transform, and compute connectivity: {fit_transform_duration:.0f} ms\"\n)\n\nprint(\n    \"\\nTime to fit, transform, and compute connectivity per epoch (window): \",\n    f\"{fit_transform_duration/(N_EPOCHS//2):.0f} ms\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Furthermore, given the noisy nature of single windows of data, there is a risk of\noverfitting the filters to this noise as opposed to the genuine interaction(s) of\ninterest. This risk is mitigated by performing the initial filter fitting on a larger\nset of data.\n\nAs a side note, it is important to consider that a multivariate approach may be as\nfast or even faster than a bivariate approach, depending on the number of connections\nand degree of rank subspace projection being performed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Time transforming data of each epoch iteratively\nstart = time.time()\nfor epoch in epochs[N_EPOCHS // 2 :]:\n    spectral_connectivity_epochs(\n        np.expand_dims(epoch, axis=0),\n        method=\"coh\",\n        indices=seed_target_indices(seeds, targets),\n        fmin=5,\n        fmax=35,\n        sfreq=epochs.info[\"sfreq\"],\n    )\nduration = (time.time() - start) * 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this instance, the standard bivariate approach is slower than the decomposition\nclass approach above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Show compute times of bivariate connectivity\nprint(f\"Time to compute connectivity: {duration:.0f} ms\")\n\nprint(\n    \"\\nTime to compute connectivity per epoch (window): \",\n    f\"{duration/(N_EPOCHS//2):.0f} ms\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Altogether, the decomposition class also offers an efficient way to analyse\nconnectivity in a specific frequency band when fitting filters to one piece of data\nand transforming other pieces of data.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Component specificity of filters\nWe have spoken much about how the filters extract particular components of\nconnectivity, which we elaborate on here. The filters act as spatial weights,\ncontrolling how much each channel contributes to the given connectivity component.\nAlthough we fit these filters to a specific frequency band, they do not operate in a\nfrequency-specific manner.\n\nFor example, say you have two sets of data: *Data 1* with an interaction at 15-20 Hz;\nand *Data 2* with an interaction at 5-10 Hz. We fit the filters at 15-20 Hz to *Data\n1*, and apply the filters to *Data 2*.\n\nIf the connectivity components in *Data 1* and *Data 2* have different spatial\ndistributions (i.e. different channels contribute to connectivity in each set of\ndata), the filters fit to 15-20 Hz on *Data 1* will not extract the 5-10 Hz\nconnectivity from *Data 2*.\n\nOn the other hand, if the connectivity components in *Data 1* and *Data 2* have the\nsame spatial distribution (i.e. the same channels contribute to connectivity in both\nsets of data), the filters fit to 15-20 Hz on *Data 1* will extract the 5-10 Hz\nconnectivity from *Data 2*. Because of this, it is generally recommended that you only\nconsider the connectivity results for those frequencies where you originally fit the\nfilters.\n\nFurthermore, if *Data 1* and *Data 2* both have interactions at the same frequency\nband (e.g. 15-20 Hz) but with different spatial distributions, the filters fit to\n15-20 Hz on *Data 1* will not extract the 15-20 Hz connectivity from *Data 2*. This is\nbecause the filters extract connectivity components according to particular spatial\ndistributions, and if the spatial distributions differ, these interactions are by\ndefinition distinct components, even if they occur at the same frequencies.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limitations\nFinally, it is important to discuss a key limitation of the decoding module approach:\nthe need to define a specific frequency band. Defining this band requires some\nexisting knowledge about your data or the oscillatory activity you are studying. This\ninsight may come from a pilot study where a frequency band of interest was identified,\na canonical frequency band defined in the literature, etc... In contrast, by fitting\nfilters to each frequency bin, the standard ``spectral_connectivity_...()`` functions\nare more data-driven.\n\nAdditionally, by applying filters fit on one set of data to another, you are assuming\nthat the connectivity components the filters are designed to extract are consistent\nacross the two sets of data. However, this may not be the case if you are applying the\nfilters to data from a distinct functional state where the spatial distribution of the\ncomponents differs. Again, by fitting filters to each new set of data passed in, the\nstandard ``spectral_connectivity_...()`` functions are more data-driven, extracting\nwhatever connectivity components are present in that data.\n\nOn these points, we note that the ``spectral_connectivity_...()`` functions complement\nthe decoding module classes well, offering a tool by which to explore your data to:\nidentify possible frequency bands of interest; and identify the spatial distributions\nof connectivity components to determine if they are consistent across different\nportions of the data.\n\nUltimately, there are distinct advantages and disadvantages to both approaches, and\none may be more suitable than the other depending on your use case.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}